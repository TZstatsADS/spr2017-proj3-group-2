---
title: "Project 3: Main Script"
author: "Group 2"
date: "March 24, 2017"
output:
  pdf_document: default
  html_document: default
---

This file is currently a template for running evaluation experiments of image analysis (or any predictive modeling). You should update it according to your codes but following precisely the same structure. 

```{r} 
#Load (and install if necessary) required packages
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}

if(!require("gbm")){
  install.packages("gbm")
}

library("EBImage")
library("gbm")
```

### Step 0: specify directories.

Set the working directory to the image folder. Specify the training and the testing set. For data without an independent test/validation set, you need to create your own testing data by random subsampling. In order to obain reproducible results, set.seed() whenever randomization is used. 

Provide directories for raw images. Training set and test set should be in different subfolders. 
```{r}
experiment_dir <- "../data/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
```

### Set up controls for evaluation experiments.

In this chunk, ,we have a set of controls for the evaluation experiments. 

+ (T/F) train 'best' model
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent test set
+ (T/F) run evaluation on an independent test set

```{r exp_setup}
run.train=TRUE # train 'best' model 
run.feature.train=TRUE # process features for training set
run.test=FALSE # run evaluation on an independent test set
run.feature.test=FALSE # process features for test set
```

### Import class labels for training images  
We code labradoodles as "1" and fried chicken as "0" for binary classification.

```{r training_images}
train_labels <- train_labels <- read.csv("data/train/labels.csv")
train_labels <- as.matrix(train_labels)[,1]
```

### Construct visual features
Save the constructed features to the output subfolder.

`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features that are required by all the models you are going to evaluate later. 

```{r feature}
source("../lib/feature.R")

tm_feature_train <- NA
if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(img_train_dir, 
                                                       "train", 
                                                       data_name="zip", 
                                                       export=TRUE))
}

tm_feature_test <- NA
if(run.feature.test){
  tm_feature_test <- system.time(dat_test <- feature(img_test_dir, 
                                                     "test", 
                                                     data_name="zip", 
                                                     export=TRUE))
}

#save(dat_train, file="./output/feature_train.RData")
#save(dat_test, file="./output/feature_test.RData")
```

### Step 4: Train a classification model with training images
Call the train model and test model from library. 

`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. 
+ `train.R`
  + Input: an R object that contains processed training set features.
  + Input: an R object of training sample labels.
  + Output: an RData file that contains trained classifiers in the forms of R objects: models/settings/links to external trained configurations.
+ `test.R`
  + Input: a path that points to the test set features.
  + Input: an R object that contains a trained classifiers.
  + Output: an R object of class label predictions on the test set. If there are multiple classifiers under evaluation, there should be multiple sets of label predictions. 
```{r loadlib}
source("../lib/train.R")
source("../lib/test.R")
```

* Train the baseline and advanced models with the entire training set using the selected models ('best' model parameters) via cross-validation.
```{r final_train}
tm_train=NA
if(run.train){
  load(file="../output/feature_train.RData")
  tm_train <- system.time(fit_train <- train(dat_train, train_labels))
  save(fit_train, file="../output/fit_train.RData")
}
```

### Make prediction 
Feed the final training model with the completely holdout testing data. 
```{r test}
tm_test=NA
if(run.test){
  load(file=paste0("../output/feature_test.RData"))
  load(file="../output/fit_train.RData")
  tm_test <- system.time(pred_test <- test(fit_train, dat_test))
  save(pred_test, file="../output/pred_test.RData")
}

```

### Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
```
