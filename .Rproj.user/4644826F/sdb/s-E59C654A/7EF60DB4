{
    "collab_server" : "",
    "contents" : "### Author: Ka Heng (Helen) Lo\n### Project 3\n### ADS Spring 2017\n######################################################\n### Fit the classification model with testing data ###\n######################################################\n\n\ntest <- function(fit_train, dat_test_base=NULL, dat_test_adv=NULL, model=\"both\"){\n  \n  ### Fit the classfication model with testing data\n  \n  ### Input: \n  ###  - list of fitted classification model(s) and prediction parameter(s) using training data\n  ###  - processed features from testing images \n  ###  -  R object that contains SIFT features of testing images\n  ###  -  R object that contains new features (SIFT-resize+adaptive) of testing images\n  ### Output: a vector of predictions for single specified model; \n  ###         or a list of two prediction vectors ($baseline_pred and $advanced_pred)\n  \n  ### load libraries\n  library(gbm)\n  library(xgboost)\n  \n  if (model == \"both\"){\n  ##########============BASELINE MODEL============##########\n  #fit_train$baseline_fit is a gbm.object class object\n    pred_base <- predict(fit_train$baseline_fit, newdata=dat_test_base, \n                         n.trees = fit_train$base_best_iter,\n                         type=\"response\")\n  \n  ##########============ADVANCED MODEL============##########\n  #fit_train$advanced_fit is a xgb.Booster class object\n    pred_adv <- predict(fit_train$advanced_fit, newdata=dat_test_adv)\n                        #Note: Since we pass a xgb.Booster model object already fitted\n                        #      with the best nrounds parameter (i.e. best iteration/n.trees\n                        #      for boosting), then we can leave out the\n                       #      ntreelimit = fit_train$adv_best_iter parameter in predict.xgb.Booster().\n                       #      The predictions are the same with & without the ntreelimit parameter.\n                       \n\n  ##########============OUTPUT DATA============##########\n  # TRUE=1; FALSE=0\n  # Labradoodle=1; Fried Chicken=0\n    output <- list(baseline_pred=as.numeric(pred_base > 0.5), \n                   advanced_pred=as.numeric(pred_adv > 0.5))\n    return(output)\n  }\n  \n  else if (model == \"base\"){\n    ##########============BASELINE MODEL============##########\n    #fit_train$baseline_fit is a gbm.object class object\n    pred_base <- predict(fit_train$baseline_fit, newdata=dat_test_base, \n                         n.trees = fit_train$base_best_iter,\n                         type=\"response\")\n    \n    output_base <- as.numeric(pred_base > 0.5)\n    return(output_base)\n  }\n  \n  else if (model == \"advanced\"){\n    ##########============ADVANCED MODEL============##########\n    #fit_train$advanced_fit is a xgb.Booster class object\n    pred_adv <- predict(fit_train$advanced_fit, newdata=dat_test_adv)\n    \n    output_adv <- as.numeric(pred_adv > 0.5)\n    return(output_adv)\n  }\n}\n\n",
    "created" : 1490151295851.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1236398379",
    "id" : "7EF60DB4",
    "lastKnownWriteTime" : 1490305000,
    "last_content_update" : 1490305000572,
    "path" : "~/Desktop/Applied Data Science/Proj3/spr2017-proj3-group-2/lib/test.R",
    "project_path" : "lib/test.R",
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}