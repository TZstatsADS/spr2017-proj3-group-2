{
    "collab_server" : "",
    "contents" : "#######if not install mxnet, run the following code#####\n#install.packages(\"drat\", repos=\"https://cran.rstudio.com\")\n#    drat:::addRepo(\"dmlc\")\n#    install.packages(\"mxnet\")\n##########\n\n#img_dir <- \"data/train/raw_images\" #change to image directory\n#label <- read.csv(\"data/train/labels.csv\")\n#label <- as.numeric(unlist(label))\nto.rezise.split(img_dir,labels){ #note: labels are numerical values\n  library(EBImage)\n  library(stringr)\n  require(mxnet)\n\n  # This script is used to resize images to 28x28 pixels\n\n  #img_dir <- \"data/train/raw_images\" #change to image directory\n  n_files <- length(list.files(img_dir))\n  #label <- read.csv(\"data/train/labels.csv\")\n  #label <- as.numeric(unlist(label))\n  imgvec <- matrix(NA, ncol = 28*28,nrow = 2000)\n  for(i in 1:n_files){\n    ii <- str_pad(i, 4, pad = \"0\")\n    img <- readImage(paste0(img_dir, \"/\",\"image_\", ii,\".jpg\"))\n    img1 <- resize(img,28,28)\n    img1.scale <- img1/max(img1)\n    img2 <- as.vector(img1)\n    imgvec[i,] <- img2\n  }\n\n  # Train-test split\n  set.seed(1)\n  chitr <- sample(1:1000,900,replace = F)\n  dogtr <- sample(1001:2000,900,replace = F)\n  train.data <- imgvec[c(chitr,dogtr),]\n  train.label <- label[c(chitr,dogtr)]\n  test.data <- imgvec[-c(chitr,dogtr),]\n  test.label <- label[-c(chitr,dogtr)]\n  train <- data.frame(cbind(train.label,train.data))\n  test <- data.frame(cbind(test.label,test.data))\n\n  colnames(train) <- c(\"label\", paste(\"pixel\", c(1:784)))\n  colnames(test) <- c(\"label\", paste(\"pixel\", c(1:784)))\n\n  write.csv(train,\"output/train_cnn.csv\",row.names = F)\n  write.csv(test,\"output/test_cnn.csv\",row.names = F)\n\n  # Load train and test datasets\n  train <- read.csv(\"train_cnn.csv\",header = T)\n  test <- read.csv(\"test_cnn.csv\",header = T)\n  output <- list(train_data = train,test_data = test)\n  return(output)\n  }\n\n\nCNN <- function(train,test){\nstart.time <- Sys.time()\ntrain <- data.matrix(train)\ntrain_x <- t(train[, -1])\ntrain_y <- train[, 1]\ntrain_array <- train_x\ndim(train_array) <- c(28, 28, 1, ncol(train_x))\n\ntest_x <- t(test[, -1])\ntest_y <- test[, 1]\ntest_array <- test_x\ndim(test_array) <- c(28, 28, 1, ncol(test_x))\n\n\ndata <- mx.symbol.Variable('data')\n# 1st convolutional layer\nconv_1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 20)\ntanh_1 <- mx.symbol.Activation(data = conv_1, act_type = \"tanh\")\npool_1 <- mx.symbol.Pooling(data = tanh_1, pool_type = \"max\", kernel = c(2, 2), stride = c(2, 2))\n# 2nd convolutional layer\nconv_2 <- mx.symbol.Convolution(data = pool_1, kernel = c(5, 5), num_filter = 50)\ntanh_2 <- mx.symbol.Activation(data = conv_2, act_type = \"tanh\")\npool_2 <- mx.symbol.Pooling(data=tanh_2, pool_type = \"max\", kernel = c(2, 2), stride = c(2, 2))\n# 1st fully connected layer\nflatten <- mx.symbol.Flatten(data = pool_2)\nfc_1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 500)\ntanh_3 <- mx.symbol.Activation(data = fc_1, act_type = \"tanh\")\n# 2nd fully connected layer\nfc_2 <- mx.symbol.FullyConnected(data = tanh_3, num_hidden = 40)\n# Output. Softmax output since we'd like to get some probabilities.\nNN_model <- mx.symbol.SoftmaxOutput(data = fc_2)\n\n# Set seed for reproducibility\nmx.set.seed(100)\ndevices <- mx.cpu()\n\n\n#retrain the model using best num.round parameter\nmodel <- mx.model.FeedForward.create(NN_model,\n                                     X = train_array,\n                                     y = train_y,\n                                     ctx = devices,\n                                     num.round =60,\n                                     array.batch.size = 40,\n                                     learning.rate = 0.01,\n                                     momentum = 0.9,\n                                     eval.metric = mx.metric.accuracy,\n                                     epoch.end.callback = mx.callback.log.train.metric(100))\n\npredicted <- predict(model, test_array)\n# Assign labels\npredicted_labels <- max.col(t(predicted)) - 1\n# Get accuracy\nerrorrate <- sum(diag(table(test[, 1], predicted_labels)))/200\nend.time <- Sys.time()\nruntime <- end.time-start.time\nsaveRDS(model,\"summary_best_CNN.rds\")\ncat(\"the test error is:\",errorrate,'\\n',\"the running time is:\",runtime,\"s\")\nouput <- list(test_err = errorrate, train_time = runtime)\nreturn(output)\n}\n",
    "created" : 1490300079587.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4067925674",
    "id" : "B60D36C2",
    "lastKnownWriteTime" : 1490313849,
    "last_content_update" : 1490313849201,
    "path" : "~/Desktop/Applied Data Science/Proj3/spr2017-proj3-group-2/lib/CNN.R",
    "project_path" : "lib/CNN.R",
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}